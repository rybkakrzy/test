Krótka odpowiedź: tak, „pending” może wynikać z frontu (Angular). Najczęściej dzieje się to przez złą konfigurację uploadu po stronie przeglądarki/Angulara albo przez coś, co blokuje samo wysłanie żądania (preflight, interceptory, service worker, limit gniazd). Poniżej checklista rzeczy, które realnie powodują „pending 0 B” i jak je wykryć/naprawić.

Co w Angularze najczęściej psuje upload

Ustawiasz ręcznie Content-Type: multipart/form-data

Skutek: brak boundary → serwer nie potrafi odczytać body, a czasem request „wisi”.

Fix: dla FormData nie ustawiaj Content-Type. Przeglądarka zrobi to sama.

const fd = new FormData();
fd.append('file', file, file.name);
this.http.post('/api/upload', fd, { reportProgress: true, observe: 'events' });


HttpInterceptor dokleja nagłówki do każdego requestu

Typowe: Content-Type, Accept, Authorization, transformacja ciała itp.

Fix: w interceptorze rozróżniaj FormData i usuń Content-Type:

@Injectable()
export class NoContentTypeForFormDataInterceptor implements HttpInterceptor {
  intercept(req: HttpRequest<any>, next: HttpHandler) {
    const isFormData = req.body instanceof FormData;
    const clean = isFormData ? req.clone({ setHeaders: { } }) : req;
    // Upewnij się, że NIE ustawiasz Content-Type dla FormData
    return next.handle(clean);
  }
}


CORS / preflight (OPTIONS) nie przechodzi

Objawy: właściwy POST nie startuje; w Network widać tylko OPTIONS, a POST jest „pending” lub wcale.

Fix: po stronie serwera/Nginx zwróć 204 dla OPTIONS i odpowiednie nagłówki lub skonfiguruj CORS w .NET.

Service Worker (PWA) łapie żądania

Objawy: „pending” albo dziwne cache’owanie; w DevTools → Application → Service Workers.

Fix: wyłącz SW na próbę (checkbox „Bypass for network”) albo wyklucz /api/** w ngsw-config.json.

Limit gniazd w przeglądarce (HTTP/1.1)

Przeglądarki mają ~6 równoległych połączeń na origin. Jeśli masz SSE/SignalR/dużo XHR, nowy upload czeka → „(Stalled) / (Pending)”.

Fix: włącz HTTP/2 w Nginx albo ogranicz równoległość w kliencie.

Czytasz/obrabiasz plik po stronie klienta przed wysyłką

Np. FileReader + hash/kompresja → długo nic się nie dzieje, wygląda jak „pending”.

Fix: ogranicz preprocessing, wrzuć go do Web Workera albo wysyłaj bezpośrednio.

withCredentials: true wywołuje preflight i serwer go nie obsługuje

Fix: włącz CORS dla poświadczeń lub nie wysyłaj cookies, jeśli nie są potrzebne.

RxJS/Angular: request wcale nie startuje

Np. brak subscribe(), takeUntil anuluje zbyt wcześnie, guard/interceptor zwraca EMPTY.

Fix: sprawdź, czy faktycznie subskrybujesz i nie anulujesz strumienia.

Minimalny „bezpieczny” upload w Angular 18
upload(file: File) {
  const form = new FormData();
  form.append('file', file, file.name); // podaj nazwę pliku

  return this.http.post('/api/upload', form, {
    reportProgress: true,
    observe: 'events',     // dostaniesz ProgressEvent
    // NIE ustawiaj headers: {'Content-Type': ...}
    // withCredentials: true  // tylko jeśli naprawdę potrzebujesz cookies
  });
}


UI do debugowania progresu:

this.upload(file).subscribe(event => {
  if (event.type === HttpEventType.UploadProgress && event.total) {
    const percent = Math.round(100 * event.loaded / event.total);
    // pokaż procent
  } else if (event.type === HttpEventType.Response) {
    // zakończone
  }
}, err => {
  // obsługa błędu
});

Jak rozpoznać, że to front (a nie Nginx/.NET)

W DevTools → Network → Waterfall:

„Queuing/Waiting for available socket” trwa długo → limit gniazd (pkt 5).

Widać OPTIONS i brak odpowiedzi → CORS/preflight (pkt 3).

Request ma Request Payload i od razu leci, ale brak odpowiedzi i Size 0 B → częściej backend/proxy; potwierdź curl -v -F "file=@..." http://host/api/upload -H "Expect:".

Zrób test POST do „/api/_upload-test” (endpoint, który tylko spala body) – jeśli działa, front jest OK, problem dalej jest po stronie Nginx/.NET/dysku.

Szybkie „twarde” reguły dla frontu

Dla FormData nigdy nie ustawiaj Content-Type.

Uważaj na interceptory – nie dokładamy nagłówków do FormData.

Unikaj zbędnego odczytu pliku w JS; jeśli musisz – użyj Web Worker.

Gdy masz dużo równoległych połączeń – rozważ HTTP/2 i/lub ogranicz concurrency.

Jeśli różne originy → poprawny CORS i obsługa OPTIONS.

Jeśli pokażesz krótki fragment z Twojego serwisu Angular (metoda uploadu + interceptory) i screen z Waterfalla (kolumna „Timing”), powiem dokładnie, czy tu jest pies pogrzebany, czy trzeba wrócić do Nginxa/OS.




Widzę Twój plik konfiguracyjny Nginx 🙂
Masz tam serwer słuchający na porcie 15222, zdefiniowany access_log (/doc2/pocz2/nginx/access.log combined) i kilka location kierujących na backendy przez proxy_pass.

Żeby logi były maksymalnie szczegółowe (zarówno dla błędów, jak i ruchu HTTP), możesz dodać globalnie w sekcji http coś w tym stylu:

http {
    include       mime.types;
    default_type  application/octet-stream;
    client_max_body_size 200M;

    # Error log z pełnym poziomem szczegółowości
    error_log /doc2/pocz2/nginx/error.log debug;

    # Własny, rozbudowany format logów
    log_format detailed '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent" '
                        'rt=$request_time '
                        'ua="$upstream_addr" us="$upstream_status" '
                        'ut="$upstream_response_time" '
                        'cs=$upstream_cache_status';

    # Domyślnie wszystkie serwery korzystają z tego access loga
    access_log /doc2/pocz2/nginx/access.log detailed;

    server {
        listen       15222;
        server_name  localhost;

        root   /usr/share/nginx/html;
        index  index.html;

        # Twoje lokacje:
        location / {
            try_files $uri $uri/ /index.html =404;
        }

        location /FormsWebApp/ {
            proxy_pass http://localhost:4200;
            proxy_set_header Host $host;
        }

        location /FormsRedirector/ {
            proxy_pass http://localhost:4300;
            proxy_set_header Host $host;
        }
    }
}

Co się zmienia:

error_log ... debug; – dostaniesz wszystkie poziomy błędów (od krytycznych po debug).

log_format detailed – dużo bogatsze logi access niż combined (masz czas requestu, info o upstreamach, status cache).

access_log ... detailed; – wymuszasz użycie tego formatu.

📌 Uwaga praktyczna:

W środowisku produkcyjnym raczej nie zostawiaj debug, bo logi urosną w szalonym tempie i mogą mocno obciążyć serwer. Najlepiej wtedy trzymać error lub warn.

Dla debugowania / dev/staging – opcja debug plus szczegółowe access logi sprawdzi się świetnie.

Chcesz, żebym Ci przygotował dwa warianty tego pliku?
👉 jeden do dev/testów (maksymalny szczegół),
👉 drugi do produkcji (lekki, ale nadal użyteczny do diagnozy)?

-------------------




# =========================
# Global process settings
# =========================
user  nginx;                  # <<< On Debian/Ubuntu use: www-data
worker_processes auto;
pid /run/nginx.pid;
worker_rlimit_nofile 200000;

events {
    worker_connections  65535;
    multi_accept on;
    # debug_connection 1.2.3.4;   # (optional) limit 'debug' logs to your IP during investigation
}

# =========================
# HTTP (web) settings
# =========================
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    charset       utf-8;

    # -------- Access logs (rich JSON) --------
    log_subrequest on;  # log internal redirects/subrequests (useful for SPA)
    log_format main_json escape=json
      '{'
        '"time":"$time_iso8601",'
        '"remote":"$remote_addr",'
        '"host":"$host",'
        '"method":"$request_method",'
        '"uri":"$request_uri",'
        '"status":$status,'
        '"req_len":$request_length,'
        '"sent":$body_bytes_sent,'
        '"req_time":$request_time,'
        '"up_addr":"$upstream_addr",'
        '"up_status":"$upstream_status",'
        '"up_connect_time":"$upstream_connect_time",'
        '"up_header_time":"$upstream_header_time",'
        '"up_resp_time":"$upstream_response_time",'
        '"ref":"$http_referer",'
        '"ua":"$http_user_agent",'
        '"cache":"$upstream_cache_status",'
        '"conn":"$connection",'
        '"conn_reqs":"$connection_requests",'
        '"pipe":"$pipe"'
      '}';
    access_log /var/log/nginx/access.json main_json buffer=256k flush=1s gzip;

    # Error log level:
    # - info: recommended default
    # - debug: only temporarily (VERY verbose)
    error_log  /var/log/nginx/error.log info;

    # -------- Performance/networking --------
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65s;
    keepalive_requests 1000;
    server_tokens off;
    reset_timedout_connection on;
    open_log_file_cache max=1000 inactive=30s valid=1m min_uses=2;

    # -------- Upload-friendly limits/timeouts --------
    client_max_body_size  512m;    # align with backend limits
    client_body_timeout   600s;
    send_timeout          600s;
    large_client_header_buffers 8 64k;

    # Move temporary files to a large/fast volume (create and chown to nginx)
    client_body_temp_path  /data/nginx/body  1 2;
    proxy_temp_path        /data/nginx/proxy 1 2;

    # -------- Gzip for text assets --------
    gzip on;
    gzip_comp_level 5;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_types
      text/plain text/css application/json application/javascript
      application/xml application/rss+xml application/vnd.ms-fontobject
      application/x-font-ttf font/opentype image/svg+xml;

    # -------- Upstream to .NET/Kestrel --------
    upstream dotnet_backend {
        server 127.0.0.1:51111 max_fails=3 fail_timeout=10s;   # <<< CHANGE ME (host:port)
        keepalive 64;  # keep persistent connections to backend
    }

    # WebSocket upgrade mapping (harmless if unused)
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    # =========================
    # Server (Angular + API)
    # =========================
    server {
        listen      80;             # <<< CHANGE to 443 with TLS if needed
        server_name _;

        # --- Security headers (safe defaults) ---
        add_header X-Content-Type-Options nosniff always;
        add_header X-Frame-Options SAMEORIGIN always;
        add_header X-XSS-Protection "1; mode=block" always;

        # --- SPA (Angular) static files ---
        root  /var/www/angular-dist;     # <<< CHANGE ME (Angular dist path)
        index index.html;

        # Cache immutable assets aggressively
        location ~* \.(?:js|mjs|css|png|jpg|jpeg|gif|webp|svg|ico|woff2?|ttf)$ {
            access_log off;
            expires 30d;
            add_header Cache-Control "public, max-age=2592000, immutable";
            try_files $uri =404;
        }

        # SPA fallback for client-side routes
        location / {
            try_files $uri $uri/ /index.html;
        }

        # --- API → .NET 8 (reverse proxy) ---
        location /api/ {
            proxy_http_version 1.1;

            # Remove 'Expect: 100-continue' that sometimes breaks uploads
            proxy_set_header Expect "";

            proxy_set_header Host               $host;
            proxy_set_header X-Forwarded-For    $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto  $scheme;

            # Let Nginx buffer request bodies to temp dir first (safer for .NET)
            proxy_request_buffering on;

            # Generous timeouts for large/slow uploads
            proxy_connect_timeout 30s;
            proxy_send_timeout    600s;
            proxy_read_timeout    600s;

            # Optional per-location log file (still JSON)
            access_log /var/log/nginx/api_access.json main_json buffer=256k flush=1s gzip;

            proxy_pass http://dotnet_backend;
        }

        # Optional runtime stats (limit access!)
        location /nginx_status {
            stub_status on;
            allow 127.0.0.1;
            # allow 10.0.0.0/8;   # <<< your CIDR if needed
            deny all;
        }

        # Simple error page (everything is logged in error.log anyway)
        error_page 500 502 503 504 /50x.html;
        location = /50x.html { internal; return 500 "Internal error\n"; }
    }

    # --- Optionally include other vhosts here ---
    # include /etc/nginx/conf.d/*.conf;
}
